# app.py
# Python 3.11 / Streamlit Community Cloudå¯¾å¿œ
# ãƒ­ãƒ¼ã‚«ãƒ«ã§ã¯ .env ã‹ã‚‰ OPENAI_API_KEY ã‚’èª­ã¿è¾¼ã‚€
# æœ¬ç•ªã§ã¯ Streamlit Secrets ã® OPENAI_API_KEY ã‚’èª­ã‚€

import os
import streamlit as st
from dotenv import load_dotenv

from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage


def get_api_key() -> str:
    """
    1. ãƒ­ãƒ¼ã‚«ãƒ«:
       .env ã® OPENAI_API_KEY ã‚’ load_dotenv() ã§èª­ã¿è¾¼ã¿ -> os.getenv()
    2. ãƒ‡ãƒ—ãƒ­ã‚¤:
       Streamlit Community Cloud ã® Secrets ã® OPENAI_API_KEY ã‚’å‚ç…§
    """
    # ãƒ­ãƒ¼ã‚«ãƒ«ç”¨ã« .env ã‚’èª­ã‚€
    load_dotenv()

    # ã¾ãšç’°å¢ƒå¤‰æ•°ã‹ã‚‰è©¦ã™
    key = os.getenv("OPENAI_API_KEY")
    if key:
        return key

    # Streamlit Cloud ã® Secrets ã‹ã‚‰è©¦ã™
    if "OPENAI_API_KEY" in st.secrets:
        return st.secrets["OPENAI_API_KEY"]

    # ã©ã“ã«ã‚‚ç„¡ã„å ´åˆ
    raise ValueError(
        "OPENAI_API_KEY ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚\n"
        ".env ã« OPENAI_API_KEY=... ã‚’æ›¸ãã‹ã€"
        "ãƒ‡ãƒ—ãƒ­ã‚¤æ™‚ã¯Streamlitã®Secretsã«OPENAI_API_KEYã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚"
    )


@st.cache_resource(show_spinner=False)
def get_llm():
    """
    LangChain ã® ChatOpenAI ã‚’åˆæœŸåŒ–ã—ã¦è¿”ã™ã€‚
    ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã¦è¤‡æ•°å›ä½¿ã„å›ã™ã€‚
    """
    api_key = get_api_key()

    llm = ChatOpenAI(
        model="gpt-4o-mini",
        temperature=0.4,
        api_key=api_key,
    )
    return llm


def build_system_prompt(expert_choice: str) -> str:
    """
    ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã®é¸æŠè‚¢ã«å¿œã˜ãŸã€Œå°‚é–€å®¶ã‚­ãƒ£ãƒ©ã€ã®ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿”ã™ã€‚
    """
    if expert_choice == "åŒ»ç™‚ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆ":
        return (
            "ã‚ãªãŸã¯ç—…é™¢çµŒå–¶ã¨è‡¨åºŠç¾å ´ã®ä¸¡æ–¹ã«è©³ã—ã„åŒ»ç™‚ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆã§ã™ã€‚"
            "åŒ»ç™‚å®‰å…¨ã€ç¾å ´ã‚ªãƒšãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã€äººå“¡é…ç½®ã€æ‚£è€…èª¬æ˜ã®ãƒªã‚¹ã‚¯ç®¡ç†ã«ã¤ã„ã¦ã€"
            "ç¾å®Ÿçš„ã§å®Ÿè¡Œå¯èƒ½ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æç¤ºã—ã¦ãã ã•ã„ã€‚"
            "å°‚é–€ç”¨èªã¯ä½¿ã£ã¦ã‚‚ã‚ˆã„ã§ã™ãŒã€å¿…è¦ã«å¿œã˜ã¦å¹³æ˜“ãªèª¬æ˜ã‚‚åŠ ãˆã¦ãã ã•ã„ã€‚"
        )

    elif expert_choice == "ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—çµŒå–¶ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼":
        return (
            "ã‚ãªãŸã¯ã‚·ãƒ¼ãƒ‰ã€œã‚·ãƒªãƒ¼ã‚ºAæ®µéšã®ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—çµŒå–¶ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼ã§ã™ã€‚"
            "æ¡ç”¨ã€è³‡é‡‘ç¹°ã‚Šã€äº‹æ¥­ã®å„ªå…ˆé †ä½ä»˜ã‘ã€ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆã®çµã‚Šè¾¼ã¿ã€"
            "ãƒãƒ¼ãƒ ãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆãªã©ã«ã¤ã„ã¦ã€æ˜æ—¥ã‹ã‚‰å‹•ã‘ã‚‹å…·ä½“çš„ãªåŠ©è¨€ã‚’ã—ã¦ãã ã•ã„ã€‚"
            "æœºä¸Šã®ç©ºè«–ã§ã¯ãªãã€å®Ÿå‹™ã«è½ã¨ã—è¾¼ã‚“ã§ãã ã•ã„ã€‚"
        )

    # å¿µã®ãŸã‚ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
    return (
        "ã‚ãªãŸã¯ä¸å¯§ã§èª å®Ÿãªå°‚é–€å®¶ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"
        "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«å¯¾ã—ã€ã‚ã‹ã‚Šã‚„ã™ããƒ»å®Ÿç”¨çš„ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚"
    )


def ask_llm(user_input: str, expert_choice: str) -> str:
    """
    ã€èª²é¡Œè¦ä»¶ã®é–¢æ•°ã€‘
    - å¼•æ•°:
        user_input: ç”»é¢ã®ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›
        expert_choice: ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã§é¸ã‚“ã å°‚é–€å®¶ãƒ­ãƒ¼ãƒ«
    - æˆ»ã‚Šå€¤:
        LLMã‹ã‚‰ã®å›ç­”ãƒ†ã‚­ã‚¹ãƒˆ
    - LangChainçµŒç”±ã§LLMã‚’å‘¼ã³å‡ºã™
    """
    llm = get_llm()
    system_prompt = build_system_prompt(expert_choice)

    messages = [
        SystemMessage(content=system_prompt),
        HumanMessage(content=user_input),
    ]

    # LangChainã®ChatOpenAIã¯ .invoke(messages) ã§å®Ÿè¡Œã§ãã‚‹
    response = llm.invoke(messages)

    # å¿œç­”ã¯ ChatMessageå‹ã§è¿”ã£ã¦ãã‚‹ã®ã§ .content ã‚’èª­ã‚€
    return response.content


# =======================
# Streamlit UI
# =======================

st.set_page_config(
    page_title="LLMç›¸è«‡ã‚¢ãƒ—ãƒª",
    page_icon="ğŸ’¬",
    layout="centered",
)

st.title("ğŸ’¬ LLMç›¸è«‡ã‚¢ãƒ—ãƒª")
st.caption("ã‚ãªãŸã®ç›¸è«‡ã‚’LLMã«é€ã‚Šã€é¸ã‚“ã å°‚é–€å®¶ã®è¦–ç‚¹ã§å›ç­”ã—ã¾ã™ã€‚")

st.markdown(
    """
### ä½¿ã„æ–¹
1. å›ç­”ã‚¹ã‚¿ã‚¤ãƒ«ï¼ˆå°‚é–€å®¶ã‚¤ãƒ¡ãƒ¼ã‚¸ï¼‰ã‚’é¸ã³ã¾ã™  
2. è³ªå•ãƒ»ç›¸è«‡å†…å®¹ã‚’å…¥åŠ›ã—ã¾ã™  
3. ã€Œé€ä¿¡ã€ã‚’æŠ¼ã™ã¨ã€LLMã‹ã‚‰ã®å›ç­”ãŒè¡¨ç¤ºã•ã‚Œã¾ã™  

### å°‚é–€å®¶ãƒ­ãƒ¼ãƒ«
- åŒ»ç™‚ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆ  
  - åŒ»ç™‚å®‰å…¨ã‚„ç¾å ´ã‚ªãƒšãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã€äººå“¡é…ç½®ã€èª¬æ˜ç¾©å‹™ãƒªã‚¹ã‚¯ãªã©ã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹  
- ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—çµŒå–¶ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼  
  - æ¡ç”¨ãƒ»äº‹æ¥­ã®å„ªå…ˆé †ä½ãƒ»è³‡é‡‘ã®è€ƒãˆæ–¹ãƒ»ãƒãƒ¼ãƒ é‹å–¶ãªã©ã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹  

### ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£/ã‚­ãƒ¼ç®¡ç†
- ãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¡Œæ™‚ï¼š`.env` ã« `OPENAI_API_KEY=sk-...` ã‚’ä¿å­˜ã—ã€GitHubã«ã¯ä¸Šã’ãªã„  
- ãƒ‡ãƒ—ãƒ­ã‚¤æ™‚ï¼šStreamlit Community Cloud ã® Secrets ã« `OPENAI_API_KEY` ã‚’è¨­å®š  
  ï¼ˆ.envã¯ã‚¢ãƒƒãƒ—ã—ãªã„ï¼‰  

### ãƒãƒ¼ã‚¸ãƒ§ãƒ³
- Streamlit Community Cloud å´ã® Python ã¯ 3.11 ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚
"""
)

st.divider()

expert_choice = st.radio(
    "å›ç­”ã‚¹ã‚¿ã‚¤ãƒ«ï¼ˆå°‚é–€å®¶ã®ç«‹å ´ï¼‰ã‚’é¸ã‚“ã§ãã ã•ã„ï¼š",
    options=[
        "åŒ»ç™‚ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆ",
        "ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—çµŒå–¶ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼",
    ],
)

user_input = st.text_area(
    "ç›¸è«‡å†…å®¹ãƒ»è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼š",
    placeholder="ä¾‹ï¼‰è¤‡æ•°ã®åŒ»å¸«ã§åŒã˜æ‚£è€…ã‚’è¨ºã‚‹ã¨è²¬ä»»ãŒæ›–æ˜§ã«ãªã‚Šã¾ã™ã€‚å®‰å…¨ã«å›ã™é‹ç”¨ã®è€ƒãˆæ–¹ã¯ï¼Ÿ",
    height=150,
)

if st.button("é€ä¿¡"):
    if not user_input.strip():
        st.warning("è³ªå•ãŒç©ºã§ã™ã€‚å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    else:
        with st.spinner("LLMã«å•ã„åˆã‚ã›ä¸­..."):
            try:
                answer = ask_llm(user_input, expert_choice)
                st.markdown("### å›ç­”")
                st.write(answer)
            except Exception as e:
                st.error(
                    "ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚APIã‚­ãƒ¼ã®è¨­å®šãªã©ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n\n"
                    f"è©³ç´°: {e}"
                )

st.divider()
st.caption("Powered by LangChain + OpenAI API")
