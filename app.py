import os
import streamlit as st
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage

@st.cache_resource(show_spinner=False)
def get_llm(model: str = "gpt-4o-mini", temperature: float = 0.4) -> ChatOpenAI:
    api_key = (st.secrets.get("OPENAI_API_KEY") or "").strip()
    if not api_key or not api_key.startswith("sk-"):
        st.error("ã‚µãƒ¼ãƒå´ã®è¨­å®šãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚ç®¡ç†è€…ã«é€£çµ¡ã—ã¦ãã ã•ã„ã€‚")
        st.stop()

    os.environ["OPENAI_API_KEY"] = api_key

    try:
        return ChatOpenAI(model=model, temperature=temperature, api_key=api_key)
    except TypeError:
        return ChatOpenAI(model_name=model, temperature=temperature, openai_api_key=api_key)



def build_system_prompt(expert_choice: str) -> str:
    if expert_choice == "åŒ»ç™‚ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆ":
        return (
            "ã‚ãªãŸã¯ç—…é™¢çµŒå–¶ã¨è‡¨åºŠç¾å ´ã®ä¸¡æ–¹ã«è©³ã—ã„åŒ»ç™‚ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆã§ã™ã€‚"
            "åŒ»ç™‚å®‰å…¨ã€ç¾å ´ã‚ªãƒšãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã€äººå“¡é…ç½®ã€æ‚£è€…èª¬æ˜ã®ãƒªã‚¹ã‚¯ç®¡ç†ã«ã¤ã„ã¦ã€"
            "ç¾å®Ÿçš„ã§å®Ÿè¡Œå¯èƒ½ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æç¤ºã—ã¦ãã ã•ã„ã€‚"
            "å°‚é–€ç”¨èªã¯ä½¿ã£ã¦ã‚‚ã‚ˆã„ã§ã™ãŒã€å¿…è¦ã«å¿œã˜ã¦å¹³æ˜“ãªèª¬æ˜ã‚‚åŠ ãˆã¦ãã ã•ã„ã€‚"
        )
    elif expert_choice == "ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—çµŒå–¶ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼":
        return (
            "ã‚ãªãŸã¯ã‚·ãƒ¼ãƒ‰ã€œã‚·ãƒªãƒ¼ã‚ºAæ®µéšã®ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—çµŒå–¶ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼ã§ã™ã€‚"
            "æ¡ç”¨ã€è³‡é‡‘ç¹°ã‚Šã€äº‹æ¥­ã®å„ªå…ˆé †ä½ä»˜ã‘ã€ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆã®çµã‚Šè¾¼ã¿ã€"
            "ãƒãƒ¼ãƒ ãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆãªã©ã«ã¤ã„ã¦ã€æ˜æ—¥ã‹ã‚‰å‹•ã‘ã‚‹å…·ä½“çš„ãªåŠ©è¨€ã‚’ã—ã¦ãã ã•ã„ã€‚"
            "æœºä¸Šã®ç©ºè«–ã§ã¯ãªãã€å®Ÿå‹™ã«è½ã¨ã—è¾¼ã‚“ã§ãã ã•ã„ã€‚"
        )
    return (
        "ã‚ãªãŸã¯ä¸å¯§ã§èª å®Ÿãªå°‚é–€å®¶ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"
        "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«å¯¾ã—ã€ã‚ã‹ã‚Šã‚„ã™ããƒ»å®Ÿç”¨çš„ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚"
    )

def ask_llm(user_input: str, expert_choice: str) -> str:
    llm = get_llm()
    messages = [
        SystemMessage(content=build_system_prompt(expert_choice)),
        HumanMessage(content=user_input),
    ]
    resp = llm.invoke(messages)
    return resp.content

st.set_page_config(page_title="LLMç›¸è«‡ã‚¢ãƒ—ãƒª", page_icon="ğŸ’¬", layout="centered")

st.title("ğŸ’¬ LLMç›¸è«‡ã‚¢ãƒ—ãƒª")

st.markdown(
    """
### ä½¿ã„æ–¹
1. å›ç­”ã‚¹ã‚¿ã‚¤ãƒ«ï¼ˆå°‚é–€å®¶ã‚¤ãƒ¡ãƒ¼ã‚¸ï¼‰ã‚’é¸ã³ã¾ã™  
2. è³ªå•ãƒ»ç›¸è«‡å†…å®¹ã‚’å…¥åŠ›ã—ã¾ã™  
3. ã€Œé€ä¿¡ã€ã‚’æŠ¼ã™ã¨ã€LLMã‹ã‚‰ã®å›ç­”ãŒè¡¨ç¤ºã•ã‚Œã¾ã™  

### å°‚é–€å®¶ãƒ­ãƒ¼ãƒ«
- åŒ»ç™‚ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆ  
  - åŒ»ç™‚å®‰å…¨ã‚„ç¾å ´ã‚ªãƒšãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã€äººå“¡é…ç½®ã€èª¬æ˜ç¾©å‹™ãƒªã‚¹ã‚¯ãªã©ã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹  
- ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—çµŒå–¶ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼  
  - æ¡ç”¨ãƒ»äº‹æ¥­ã®å„ªå…ˆé †ä½ãƒ»è³‡é‡‘ã®è€ƒãˆæ–¹ãƒ»ãƒãƒ¼ãƒ é‹å–¶ãªã©ã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹  
"""
)

st.divider()

expert_choice = st.radio(
    "å›ç­”ã‚¹ã‚¿ã‚¤ãƒ«ï¼ˆå°‚é–€å®¶ã®ç«‹å ´ï¼‰ã‚’é¸ã‚“ã§ãã ã•ã„ï¼š",
    options=["åŒ»ç™‚ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆ", "ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—çµŒå–¶ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼"],
)

user_input = st.text_area(
    "ç›¸è«‡å†…å®¹ãƒ»è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼š",
    placeholder="ä¾‹ï¼‰è¤‡æ•°ã®åŒ»å¸«ã§åŒã˜æ‚£è€…ã‚’è¨ºã‚‹ã¨è²¬ä»»ãŒæ›–æ˜§ã«ãªã‚Šã¾ã™ã€‚å®‰å…¨ã«å›ã™é‹ç”¨ã®è€ƒãˆæ–¹ã¯ï¼Ÿ",
    height=150,
)

if st.button("é€ä¿¡"):
    if not user_input.strip():
        st.warning("è³ªå•ãŒç©ºã§ã™ã€‚å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    else:
        with st.spinner("LLMã«å•ã„åˆã‚ã›ä¸­..."):
            try:
                answer = ask_llm(user_input, expert_choice)
                st.markdown("### å›ç­”")
                st.write(answer)
            except Exception as e:
                st.error("ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n\n" + str(e))

st.divider()
st.caption("Powered by LangChain + OpenAI API")